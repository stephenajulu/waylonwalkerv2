{"componentChunkName":"component---src-templates-blog-post-js","path":"/blog/bind-dynamic-lambdas/","result":{"data":{"markdownRemark":{"id":"453876b6-fd27-5750-8fdd-c6a881b7f603","html":"<p>This past week I had a really weird bug in my <a href=\"http://kedro.readthedocs.io/\">kedro</a> pipeline.  For some reason data running through my pipeline was coming out completely made no sense, but if I manually request raw data outside of the pipeline it matched expectations.</p>\n<p><strong>NOTE</strong> While this story is about a kedro pipeline, it can be applied anywhere closures are put into an iterable.</p>\n<h2><img src=\"https://waylonwalker.com/bind-dynamic-lambdas-1.png\" alt=\"Debugger to the rescue\"></h2>\n<p>After a few days of looking at it off and on, I pinpointed that it was all the way down in the raw layer. Right as data is coming off of the database.  For this I already had existing <code class=\"language-text\">sql</code> files stored and a <code class=\"language-text\">read_sql</code> function to get the data so I opted to just set up the pipeline to utilize the existing code as much as possible, leaning on the <a href=\"http://kedro.readthedocs.io/\">kedro</a> framework a bit less.</p>\n<p>I have dynamically created lists of pipeline nodes many times in the past, but typically I take data from <a href=\"http://kedro.readthedocs.io/\">kedro</a> input and use it in the lambda.  I prefer the simplicity of using lambdas over <code class=\"language-text\">functools.partial</code>.  It typically looks something like this.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># üëç  I do this all the time</span>\n<span class=\"token keyword\">from</span> kedro<span class=\"token punctuation\">.</span>pipeline <span class=\"token keyword\">import</span> node\n<span class=\"token keyword\">from</span> my_generic_project_lib <span class=\"token keyword\">import</span> clean\n\ndatasets_to_clean <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'sales'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'production'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'inventory'</span><span class=\"token punctuation\">]</span>\nnodes <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n<span class=\"token keyword\">for</span> dataset <span class=\"token keyword\">in</span> datasets_to_clean<span class=\"token punctuation\">:</span>\n   nodes<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>\n      node<span class=\"token punctuation\">(</span>\n         func<span class=\"token operator\">=</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> clean<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n         inputs <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f'raw_</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>dataset<span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span>\n         outputs<span class=\"token operator\">=</span><span class=\"token string-interpolation\"><span class=\"token string\">f'int_</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>dataset<span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span>\n         tags<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'int'</span><span class=\"token punctuation\">,</span> dataset<span class=\"token punctuation\">]</span>\n         name<span class=\"token operator\">=</span><span class=\"token string-interpolation\"><span class=\"token string\">f'create_int_</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>dataset<span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span>\n      <span class=\"token punctuation\">)</span>\n   <span class=\"token punctuation\">)</span></code></pre></div>\n<p>What was different this time is that I needed to pass in the name of the dataset to my read_sql function, not the data loaded in the framework.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># ‚ùå This does not work</span>\n<span class=\"token keyword\">from</span> kedro<span class=\"token punctuation\">.</span>pipeline <span class=\"token keyword\">import</span> node\n<span class=\"token keyword\">from</span> my_generic_project_lib <span class=\"token keyword\">import</span> read_sql\n\ndatasets_to_read <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'sales'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'production'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'inventory'</span><span class=\"token punctuation\">]</span>\nnodes <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n<span class=\"token keyword\">for</span> dataset <span class=\"token keyword\">in</span> datasets_to_clean<span class=\"token punctuation\">:</span>\n   nodes<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>\n      node<span class=\"token punctuation\">(</span>\n         func<span class=\"token operator\">=</span><span class=\"token keyword\">lambda</span><span class=\"token punctuation\">:</span> read_sql<span class=\"token punctuation\">(</span>dataset<span class=\"token punctuation\">)</span> <span class=\"token comment\"># üí• The major issue</span>\n         inputs <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f'dummy'</span></span>\n         outputs<span class=\"token operator\">=</span><span class=\"token string-interpolation\"><span class=\"token string\">f'int_</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>dataset<span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span>\n         tags<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'int'</span><span class=\"token punctuation\">,</span> dataset<span class=\"token punctuation\">]</span>\n         name<span class=\"token operator\">=</span><span class=\"token string-interpolation\"><span class=\"token string\">f'create_int_</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>dataset<span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span>\n      <span class=\"token punctuation\">)</span>\n   <span class=\"token punctuation\">)</span></code></pre></div>\n<h2><img src=\"https://waylonwalker.com/bind-dynamic-lambdas-2.png\" alt=\"Seriously\"></h2>\n<p>As I am still oblivious to what has happened I pop in a <code class=\"language-text\">breakpoint()</code> and quickly see that during the first run the dataset passed into <code class=\"language-text\">read_sql</code> was <code class=\"language-text\">&#39;inventory&#39;</code>, in fact, every single one was <code class=\"language-text\">&#39;inventory&#39;</code>.  The lambda is just using the latest value of dataset from outside and has no <code class=\"language-text\">local</code> <code class=\"language-text\">dataset</code> attached to it.</p>\n<h2><img src=\"https://waylonwalker.com/bind-dynamic-lambdas-3.png\" alt=\"The simple fix \"></h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># üëç Much Better</span>\n<span class=\"token keyword\">from</span> kedro<span class=\"token punctuation\">.</span>pipeline <span class=\"token keyword\">import</span> node\n<span class=\"token keyword\">from</span> my_generic_project_lib <span class=\"token keyword\">import</span> read_sql\n\ndatasets_to_read <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'sales'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'production'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'inventory'</span><span class=\"token punctuation\">]</span>\nnodes <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n<span class=\"token keyword\">for</span> dataset <span class=\"token keyword\">in</span> datasets_to_clean<span class=\"token punctuation\">:</span>\n   nodes<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>\n      node<span class=\"token punctuation\">(</span>\n         func<span class=\"token operator\">=</span><span class=\"token keyword\">lambda</span> dataset<span class=\"token operator\">=</span>dataset<span class=\"token punctuation\">:</span> read_sql<span class=\"token punctuation\">(</span>dataset<span class=\"token punctuation\">)</span> <span class=\"token comment\"># dataset is now bound to the lambda ‚ú®</span>\n         inputs <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f'dummy'</span></span>\n         outputs<span class=\"token operator\">=</span><span class=\"token string-interpolation\"><span class=\"token string\">f'int_</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>dataset<span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span>\n         tags<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'int'</span><span class=\"token punctuation\">,</span> dataset<span class=\"token punctuation\">]</span>\n         name<span class=\"token operator\">=</span><span class=\"token string-interpolation\"><span class=\"token string\">f'create_int_</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>dataset<span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span>\n      <span class=\"token punctuation\">)</span>\n   <span class=\"token punctuation\">)</span></code></pre></div>\n<h2><img src=\"https://waylonwalker.com/bind-dynamic-lambdas-4.png\" alt=\"Try it yourself\"></h2>\n<p>I made a slightly more simple example so that you can try it and play with it yourself, edit it, share it with your friends, laugh at my mistake, whatever you like.</p>\n<iframe height='400px' width='100%' src='https://repl.it/@WaylonWalker/BindDynamicLambdas?lite=true' scrolling='no' frameborder='no' allowtransparency='true' allowfullscreen='true' sandbox='allow-forms allow-pointer-lock allow-popups allow-same-origin allow-scripts allow-modals'></iframe>","fields":{"slug":"/blog/bind-dynamic-lambdas/"},"frontmatter":{"date":"2020-04-27T12:13:00.000Z","devto_url":"","devto_id":"","title":"TIL: Bind arguments to dynamically generated lambdas in python","description":"This past week I had a really weird bug in my [kedro](http://kedro.readthedocs.io/) pipeline.  For some reason data running through my pipeline was coming out completely made no sense, but if I manually request raw data outside of the pipeline it matched expectations.","path":"bind-dynamic-lambdas","twitter_cover":{"absolutePath":"/home/runner/work/waylonwalkerv2/waylonwalkerv2/static/bind-dynamic-lambdas.png","childImageSharp":{"fixed":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAIAAAB2/0i6AAAACXBIWXMAAA7EAAAOxAGVKw4bAAABmUlEQVQY02OQUzWWUNEXU9IXV9ATkdMRltMWltUSU9CVUTOW1zAFktKqRjJqRtIqhpJK+kAkASSVQQjIYLDQcQk2CbXTcbd09HXxDfcJjfMLTfDwj3L0DJFSMZJWMwbqVNQ2lVU3llQ2lFIBIUllAwmwKQxyqiY6GjaGeo7GRs7urmGuzsHaBvZaJg76Fi5KOpai8jriinrcYipABlyPhLKBuIIuSLOEsr6okp6EqqG4nI6Wvt2ESbMycsoKKxo6eqdU1rd5B8VOm7UgNbvYxNYdaIq4vJa8qY92bLe8iZeYnBYD0DwIAvpTVt1kycp1u/YemL94xdyFy/YdPNIzacbeAydWrttWVtfFK6aqaOFnmjnVNGPi/BlRgV56UM0S0JAwAHpJTsMUSALt0TN3cvQMtncwiw23DAm0MjfT4tcJqO0p/HDS6dJaawcHQwaET8AIqAfoBAgppWqkY2pvaKJvYalvZq6vb2zIJa4bFmSyd66Vg70BnzTQz0g60RDQCFDkyesLyeoLyemLyINiSEQeaK6+mCIo2gDXPGyF4lyUIgAAAABJRU5ErkJggg==","width":800,"height":418,"src":"/static/ab88674362f48f2dc57b05889e4f5380/267c5/bind-dynamic-lambdas.png","srcSet":"/static/ab88674362f48f2dc57b05889e4f5380/267c5/bind-dynamic-lambdas.png 1x"}}},"cover":{"absolutePath":"/home/runner/work/waylonwalkerv2/waylonwalkerv2/static/bind-dynamic-lambdas.png","childImageSharp":{"fixed":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAIAAAB2/0i6AAAACXBIWXMAAA7EAAAOxAGVKw4bAAABmUlEQVQY02OQUzWWUNEXU9IXV9ATkdMRltMWltUSU9CVUTOW1zAFktKqRjJqRtIqhpJK+kAkASSVQQjIYLDQcQk2CbXTcbd09HXxDfcJjfMLTfDwj3L0DJFSMZJWMwbqVNQ2lVU3llQ2lFIBIUllAwmwKQxyqiY6GjaGeo7GRs7urmGuzsHaBvZaJg76Fi5KOpai8jriinrcYipABlyPhLKBuIIuSLOEsr6okp6EqqG4nI6Wvt2ESbMycsoKKxo6eqdU1rd5B8VOm7UgNbvYxNYdaIq4vJa8qY92bLe8iZeYnBYD0DwIAvpTVt1kycp1u/YemL94xdyFy/YdPNIzacbeAydWrttWVtfFK6aqaOFnmjnVNGPi/BlRgV56UM0S0JAwAHpJTsMUSALt0TN3cvQMtncwiw23DAm0MjfT4tcJqO0p/HDS6dJaawcHQwaET8AIqAfoBAgppWqkY2pvaKJvYalvZq6vb2zIJa4bFmSyd66Vg70BnzTQz0g60RDQCFDkyesLyeoLyemLyINiSEQeaK6+mCIo2gDXPGyF4lyUIgAAAABJRU5ErkJggg==","width":1000,"height":420,"src":"/static/ab88674362f48f2dc57b05889e4f5380/a8734/bind-dynamic-lambdas.png","srcSet":"/static/ab88674362f48f2dc57b05889e4f5380/a8734/bind-dynamic-lambdas.png 1x"},"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAIAAAB2/0i6AAAACXBIWXMAAA7EAAAOxAGVKw4bAAABmUlEQVQY02OQUzWWUNEXU9IXV9ATkdMRltMWltUSU9CVUTOW1zAFktKqRjJqRtIqhpJK+kAkASSVQQjIYLDQcQk2CbXTcbd09HXxDfcJjfMLTfDwj3L0DJFSMZJWMwbqVNQ2lVU3llQ2lFIBIUllAwmwKQxyqiY6GjaGeo7GRs7urmGuzsHaBvZaJg76Fi5KOpai8jriinrcYipABlyPhLKBuIIuSLOEsr6okp6EqqG4nI6Wvt2ESbMycsoKKxo6eqdU1rd5B8VOm7UgNbvYxNYdaIq4vJa8qY92bLe8iZeYnBYD0DwIAvpTVt1kycp1u/YemL94xdyFy/YdPNIzacbeAydWrttWVtfFK6aqaOFnmjnVNGPi/BlRgV56UM0S0JAwAHpJTsMUSALt0TN3cvQMtncwiw23DAm0MjfT4tcJqO0p/HDS6dJaawcHQwaET8AIqAfoBAgppWqkY2pvaKJvYalvZq6vb2zIJa4bFmSyd66Vg70BnzTQz0g60RDQCFDkyesLyeoLyemLyINiSEQeaK6+mCIo2gDXPGyF4lyUIgAAAABJRU5ErkJggg==","aspectRatio":2.380952380952381,"src":"/static/ab88674362f48f2dc57b05889e4f5380/a8734/bind-dynamic-lambdas.png","srcSet":"/static/ab88674362f48f2dc57b05889e4f5380/2d6f8/bind-dynamic-lambdas.png 250w,\n/static/ab88674362f48f2dc57b05889e4f5380/03ac3/bind-dynamic-lambdas.png 500w,\n/static/ab88674362f48f2dc57b05889e4f5380/a8734/bind-dynamic-lambdas.png 1000w","sizes":"(max-width: 1000px) 100vw, 1000px"}}}}}},"pageContext":{"id":"453876b6-fd27-5750-8fdd-c6a881b7f603"}}}